{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running get embeddings call\n",
      "No fast path sir\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/users/jie/data-slicing/COCO/embeds/train2017_fixed_clip_only'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 99\u001b[0m\n\u001b[1;32m     97\u001b[0m embed_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/users/jie/data-slicing/COCO/embeds/train2017_fixed_clip_only\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     98\u001b[0m new_pickle_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_2017_fixed_clip_only.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 99\u001b[0m embed_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_new_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_pickle_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 85\u001b[0m, in \u001b[0;36mcreate_new_pickle\u001b[0;34m(seg_embed_dir, pickle_out_path)\u001b[0m\n\u001b[1;32m     81\u001b[0m         embed_dict \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embed_dict\n\u001b[0;32m---> 85\u001b[0m embeds, seg_ids, img_to_vec_list, vec_to_img \u001b[38;5;241m=\u001b[39m \u001b[43mload_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_embed_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m out_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: embeds, \n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: seg_ids, \n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_to_vec_list\u001b[39m\u001b[38;5;124m'\u001b[39m: img_to_vec_list,\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec_to_img\u001b[39m\u001b[38;5;124m'\u001b[39m: vec_to_img,\n\u001b[1;32m     91\u001b[0m }\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pickle_out_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m, in \u001b[0;36mload_embeddings\u001b[0;34m(fast_path_dir, seg_embeddings_dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m segment_ids_across_images \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# img_idx = []\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m imgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg_embeddings_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m img_to_vec_list \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     26\u001b[0m vector_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/users/jie/data-slicing/COCO/embeds/train2017_fixed_clip_only'"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_embeddings(fast_path_dir, seg_embeddings_dir):\n",
    "    print('Running get embeddings call')\n",
    "    if fast_path_dir and os.path.exists(fast_path_dir):\n",
    "        with open(fast_path_dir, 'rb') as f:\n",
    "            embed_dict = pickle.load(f)\n",
    "\n",
    "        print('Fast path')\n",
    "        embeddings = embed_dict['average_embeddings']\n",
    "        segment_ids_across_images = embed_dict['segment_ids']\n",
    "        return embeddings, segment_ids_across_images\n",
    "\n",
    "    print('No fast path sir')\n",
    "    average_embeddings_across_images = []\n",
    "    segment_ids_across_images = [] \n",
    "    # img_idx = []\n",
    "    imgs = sorted(os.listdir(seg_embeddings_dir))\n",
    "    img_to_vec_list = {}\n",
    "    vector_idx = 0\n",
    "    vec_to_img = [] # Maps vector index to image index\n",
    "\n",
    "    print(len(imgs))\n",
    "\n",
    "    for idx, seg_emb in enumerate(imgs):\n",
    "        seg_emb_file = os.path.join(seg_embeddings_dir, seg_emb)\n",
    "\n",
    "        try:\n",
    "            with open(seg_emb_file, \"rb\") as f:\n",
    "                dictionary = pickle.load(f)\n",
    "        except:\n",
    "            print('Error loading embeddings', seg_emb)\n",
    "            continue\n",
    "    \n",
    "        dictionary[\"average_embeddings\"] = np.load(BytesIO(dictionary[\"average_embeddings\"]))['a']\n",
    "        average_embeddings = dictionary[\"average_embeddings\"]\n",
    "        segment_ids = dictionary[\"segment_ids\"]\n",
    "        if len(segment_ids) == 0:\n",
    "            print('what')\n",
    "            continue\n",
    "\n",
    "        if segment_ids[0] == 0:\n",
    "            average_embeddings = average_embeddings[1:]\n",
    "            segment_ids = segment_ids[1:]\n",
    "\n",
    "        if len(average_embeddings) == 0:\n",
    "            continue\n",
    "\n",
    "        # Have a dictionary of image names pointing to the start and end index of the embeddings\n",
    "        img_name = seg_emb.split('.pkl')[0]\n",
    "        start_idx = vector_idx\n",
    "        # end_idx = start_idx + len(average_embeddings) - 1\n",
    "        end_idx = start_idx + len(average_embeddings)\n",
    "\n",
    "        segment_id_idx = len(segment_ids_across_images)\n",
    "        img_to_vec_list[img_name] = (start_idx, end_idx, segment_id_idx)\n",
    "        for i in range(start_idx, end_idx):\n",
    "            # vec_to_img.append(idx)\n",
    "            vec_to_img.append(img_name)\n",
    "\n",
    "        average_embeddings_across_images.append(average_embeddings)\n",
    "        segment_ids_across_images.append(segment_ids)\n",
    "\n",
    "        vector_idx += len(average_embeddings)\n",
    "        # img_idx.append(idx)\n",
    "\n",
    "\n",
    "    average_embeddings_across_images = np.vstack(average_embeddings_across_images)\n",
    "    \n",
    "    return average_embeddings_across_images, segment_ids_across_images, img_to_vec_list, vec_to_img\n",
    "\n",
    "def create_new_pickle(seg_embed_dir, pickle_out_path='coco-2014-val-clip-embeds-fast-2.pkl'):\n",
    "    if os.path.exists(pickle_out_path):\n",
    "        with open(pickle_out_path, 'rb') as f:\n",
    "            embed_dict = pickle.load(f)\n",
    "\n",
    "        return embed_dict\n",
    "\n",
    "    embeds, seg_ids, img_to_vec_list, vec_to_img = load_embeddings(None, seg_embed_dir)\n",
    "    out_dict = {\n",
    "        'average_embeddings': embeds, \n",
    "        'segment_ids': seg_ids, \n",
    "        'img_to_vec_list': img_to_vec_list,\n",
    "        'vec_to_img': vec_to_img,\n",
    "    }\n",
    "    with open(pickle_out_path, \"wb\") as f:\n",
    "        pickle.dump(out_dict, f)\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "embed_dir = '/data/users/jie/data-slicing/COCO/embeds/train2017_fixed_clip_only'\n",
    "new_pickle_path = 'train_2017_fixed_clip_only.pkl'\n",
    "embed_dict = create_new_pickle(embed_dir, new_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imagesize\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: imagesize\n",
      "Successfully installed imagesize-1.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "def process_chunk(chunk, seg_ids, embeds, img_dir, seg_dir, size_threshold):\n",
    "    results = []\n",
    "    for (idx, img, vec_info) in chunk:\n",
    "        start, end, seg_id_idx = vec_info\n",
    "        seg_id = seg_ids[seg_id_idx]\n",
    "        seg_emb = embeds[start:end]\n",
    "\n",
    "        # Fix off-by-one seg_id\n",
    "        seg_id = [i - 1 for i in seg_id]\n",
    "        seg_id_to_emb = {i: emb for i, emb in zip(seg_id, seg_emb)}\n",
    "        seg_file = os.path.join(seg_dir, img + '.json')\n",
    "        if not os.path.exists(seg_file):\n",
    "            continue\n",
    "\n",
    "        decoded_segments = load_masks(seg_file)\n",
    "        id_segments = list(enumerate(decoded_segments))\n",
    "\n",
    "        img_rgb = Image.open(os.path.join(img_dir, img)).convert('RGB')\n",
    "        \n",
    "        img_width, img_height = img_rgb.size\n",
    "        img_area = img_width * img_height\n",
    "\n",
    "        for i, (curr_seg_id, segment) in enumerate(id_segments):\n",
    "            x_min, y_min, x_max, y_max = get_box(segment)\n",
    "            box_area = (x_max - x_min) * (y_max - y_min)\n",
    "            if box_area < img_area * size_threshold:\n",
    "                continue\n",
    "\n",
    "            b_box = (x_min / img_width, y_min / img_height, x_max / img_width, y_max / img_height)\n",
    "            # b_embed = seg_emb[i]\n",
    "            b_embed = seg_id_to_emb[curr_seg_id]\n",
    "            results.append((b_box, b_embed, curr_seg_id, img))\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_box_embed_data_parallel(data, seg_ids, embeds, img_dir, seg_dir, size_threshold=0.01, num_processes=None):\n",
    "    if num_processes is None:\n",
    "        num_processes = mp.cpu_count()\n",
    "\n",
    "    # Split the data into chunks\n",
    "    chunk_size = len(data) // num_processes\n",
    "    chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "    # Create a pool of worker processes\n",
    "    with mp.Pool(num_processes) as pool:\n",
    "        # Create a partial function with fixed arguments\n",
    "        process_chunk_partial = partial(\n",
    "            process_chunk,\n",
    "            seg_ids=seg_ids,\n",
    "            embeds=embeds,\n",
    "            img_dir=img_dir,\n",
    "            seg_dir=seg_dir,\n",
    "            size_threshold=size_threshold\n",
    "        )\n",
    "\n",
    "        # Use tqdm to show progress\n",
    "        results = list(tqdm(pool.imap(process_chunk_partial, chunks), total=len(chunks), desc=\"Processing chunks\"))\n",
    "\n",
    "    # Flatten the results\n",
    "    flattened_results = [item for sublist in results for item in sublist]\n",
    "\n",
    "    # Separate the results into individual lists\n",
    "    boxes, box_embeds, box_seg_ids, box_img = zip(*flattened_results)\n",
    "\n",
    "    return list(boxes), list(box_embeds), list(box_seg_ids), list(box_img)\n",
    "\n",
    "# Usage example (to be run in a Jupyter notebook cell):\n",
    "\n",
    "box_pickle_name = new_pickle_path.split('.pkl')[0] + '_boxes.pkl'\n",
    "boxes, box_embeds, box_seg_ids, box_img = None, None, None, None\n",
    "\n",
    "if os.path.exists(box_pickle_name):\n",
    "    print(\"Load from file\")\n",
    "    with open(box_pickle_name, 'rb') as f:\n",
    "        box_data = pickle.load(f)\n",
    "\n",
    "    boxes = box_data['boxes']\n",
    "    box_embeds = box_data['embeds']\n",
    "    box_seg_ids = box_data['seg_ids']\n",
    "    box_img = box_data['img'] \n",
    "    # boxes, box_embeds, box_seg_ids, box_img = box_data\n",
    "else:\n",
    "    print(\"Load manual (long ):)\")\n",
    "    boxes, box_embeds, box_seg_ids, box_img = get_box_embed_data_parallel(\n",
    "        data, seg_ids, embeds, img_dir, seg_dir, num_processes=32\n",
    "    )\n",
    "\n",
    "    box_dict = {\n",
    "        'boxes': boxes,\n",
    "        'embeds': box_embeds,\n",
    "        'seg_ids': box_seg_ids,\n",
    "        'img': box_img\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(box_pickle_name):\n",
    "        with open('box_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(box_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
