{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running get embeddings call\n",
      "No fast path sir\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import hashlib\n",
    "from utils import create_new_pickle\n",
    "\n",
    "\n",
    "coco_path = '/data/users/jie/data-slicing/COCO/'\n",
    "# embed_path = os.path.join(coco_path, 'embeds/fixed/train2017_vitl_fixed_maskclip/')\n",
    "embed_path = os.path.join(coco_path, 'embeds/train2017_vitl_fixed_maskclip/')\n",
    "pickle_path = 'train2017_vitl_fixed_maskclip-fast.pkl'\n",
    "embed_dict = create_new_pickle(embed_path, pickle_path)\n",
    "average_embeddings = embed_dict['average_embeddings']\n",
    "dim = average_embeddings.shape[1]\n",
    "k_coarse = 1023\n",
    "m = 256\n",
    "nbits = 8\n",
    "n_probes = 20\n",
    "\n",
    "train_sample_size = int(128 * math.sqrt(average_embeddings.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.157777786254883"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_embeddings.nbytes / 1024 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict['embed_path'] = embed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is hash 31bd25a\n",
      "Building new index\n",
      "Training on subset 0.03937339717978393\n",
      "Building IVFPQ index\n",
      "Saved new index to cached_index_c70f56f8a2\n",
      "Kmeans trained (hax) 1023\n",
      "Building Flat index\n",
      "Building IVF-Flat index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 1023 points to 1023 centroids: please provide at least 39897 training points\n",
      "WARNING clustering 1023 points to 1023 centroids: please provide at least 39897 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is training embeds (416117, 512)\n",
      "521 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118287it [01:35, 1236.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "\n",
    "index_pq, index_flat_cpu, index_ivf_flat_cpu, packd, img_concept_bitmap, all_images, pqq, kmeans = \\\n",
    "    data.get_indices(dim, k_coarse, m, nbits, n_probes, embed_dict, train_sample_size=train_sample_size,\n",
    "                     build_ivf_flat=True, cache_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_bitmap_to_pyroaring(bitmap):\n",
    "    \"\"\"\n",
    "    Convert a NumPy bitmap to PyRoaring bitmaps with careful verification.\n",
    "    \n",
    "    Args:\n",
    "        bitmap: A 2D NumPy boolean array\n",
    "    \n",
    "    Returns:\n",
    "        List of PyRoaring BitMap objects, one for each column\n",
    "    \"\"\"\n",
    "    from pyroaring import BitMap\n",
    "    import numpy as np\n",
    "    \n",
    "    _, n_cols = bitmap.shape\n",
    "    roarings = []\n",
    "    \n",
    "    for col in range(n_cols):\n",
    "        # Find indices where column is True\n",
    "        indices = np.where(bitmap[:, col])[0]\n",
    "        \n",
    "        # Create BitMap from indices\n",
    "        # Important: PyRoaring requires uint32 indices\n",
    "        # roaring = BitMap(indices.astype(np.uint32))\n",
    "        roaring = BitMap(indices)\n",
    "        # Verification step\n",
    "        original_count = np.sum(bitmap[:, col])\n",
    "        roaring_count = len(roaring)\n",
    "        assert original_count == roaring_count, f\"Column {col} conversion mismatch! Original: {original_count}, Roaring: {roaring_count}\"\n",
    "        \n",
    "        \n",
    "        roarings.append(roaring)\n",
    "    \n",
    "    return roarings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans centroids: 1.998046875 MB\n",
      "packd: 2612.1956787109375 MB\n",
      "codebook: 0.5 MB\n",
      "bitmap: 115.40184116363525 MB\n",
      "sparse: 38.57171630859375 MB\n",
      "total non-sparse: 2.666 GB\n",
      "total sparse: 2.591 GB\n",
      "total roaring: 2.561 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from scipy import sparse\n",
    "from pympler import asizeof\n",
    "# our memory usage\n",
    "# * kmeans centroids\n",
    "# * quantizer codebook\n",
    "# * bitmap\n",
    "# * packd\n",
    "\n",
    "ksize_bytes = kmeans.centroids.shape[0] * kmeans.centroids.shape[1] * np.dtype(np.float32).itemsize\n",
    "packd_key_bytes = asizeof.asizeof(packd.keys)\n",
    "packd_value_bytes = len(average_embeddings) * m * nbits / 8\n",
    "packd_bytes = packd_key_bytes + packd_value_bytes\n",
    "codebook = faiss.vector_to_array(pqq.centroids).reshape(pqq.M, pqq.ksub, pqq.dsub)\n",
    "codebook_bytes = codebook.nbytes\n",
    "bitmap_bytes = img_concept_bitmap.nbytes\n",
    "sparse_mat_bytes = asizeof.asizeof(sparse.csr_matrix(img_concept_bitmap))\n",
    "roaring_bytes = asizeof.asizeof(improved_bitmap_to_pyroaring(img_concept_bitmap))\n",
    "\n",
    "print(f'kmeans centroids: {ksize_bytes / 1024 / 1024} MB')\n",
    "print(f'packd: {packd_bytes / 1024 / 1024} MB')\n",
    "print(f'codebook: {codebook_bytes / 1024 / 1024} MB')\n",
    "print(f'roaring: {roaring_bytes / 1024 / 1024} MB')\n",
    "print(f'bitmap: {bitmap_bytes / 1024 / 1024} MB')\n",
    "print(f'sparse: {sparse_mat_bytes / 1024 / 1024} MB')\n",
    "\n",
    "us_total_bytes = ksize_bytes + packd_bytes + codebook_bytes + bitmap_bytes \n",
    "print(f'total non-sparse: {us_total_bytes / 1024 / 1024 / 1024:.3f} GB')\n",
    "us_total_bytes_sparse = ksize_bytes + packd_bytes + codebook_bytes + sparse_mat_bytes\n",
    "print(f'total sparse: {us_total_bytes_sparse / 1024 / 1024 / 1024:.3f} GB')\n",
    "us_total_bytes_roaring = ksize_bytes + packd_bytes + codebook_bytes + roaring_bytes\n",
    "print(f'total roaring: {us_total_bytes_roaring / 1024 / 1024 / 1024:.3f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10568481, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans centroids: 1.998046875 MB\n",
      "inverted list: 2620.5111122131348 MB\n",
      "codebook: 0.5 MB\n",
      "total: 2.562 GB\n"
     ]
    }
   ],
   "source": [
    "# PQ memory usage\n",
    "# centroids \n",
    "# codebook\n",
    "# inverted list\n",
    "import faiss.contrib.inspect_tools\n",
    "\n",
    "def get_invlist(invlists, l):\n",
    "    \"\"\" returns the inverted lists content. \"\"\"\n",
    "    ls = invlists.list_size(l)\n",
    "    list_ids = np.zeros(ls, dtype='int32') # Can be made 32\n",
    "    x = invlists.get_ids(l)\n",
    "    faiss.memcpy(faiss.swig_ptr(list_ids), x, list_ids.nbytes)\n",
    "    invlists.release_ids(l, x)\n",
    "    x = invlists.get_codes(l)\n",
    "    list_codes = np.zeros((ls, invlists.code_size), dtype='uint8')\n",
    "    faiss.memcpy(faiss.swig_ptr(list_codes), x, list_codes.nbytes)\n",
    "    invlists.release_codes(l, x)    \n",
    "    return list_ids, list_codes\n",
    "\n",
    "\n",
    "ksize_bytes = kmeans.centroids.shape[0] * kmeans.centroids.shape[1] * np.dtype(np.float32).itemsize\n",
    "codebook = faiss.contrib.inspect_tools.get_pq_centroids(index_pq.pq)\n",
    "codebook_bytes = codebook.nbytes\n",
    "list_bytes = 0\n",
    "for i in range(index_pq.invlists.nlist):\n",
    "    list_ids, list_codes = get_invlist(index_pq.invlists, i)\n",
    "    list_bytes += list_ids.nbytes + list_codes.nbytes\n",
    "    # We ignore list_ids because we have an equivalent mapping tracking the vector ids\n",
    "    # list_bytes +=  list_codes.nbytes\n",
    "\n",
    "print(f'kmeans centroids: {ksize_bytes / 1024 / 1024} MB')\n",
    "print(f'inverted list: {list_bytes / 1024 / 1024} MB')\n",
    "print(f'codebook: {codebook_bytes / 1024 / 1024} MB')\n",
    "pq_total_bytes = ksize_bytes + list_bytes + codebook_bytes\n",
    "print(f'total: {pq_total_bytes / 1024 / 1024 / 1024:.3f} GB')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6581531"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packd.used - average_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.157777786254883"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_embeddings.nbytes / 1024 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression ratio us: 0.038512046946555634\n",
      "compression ratio pq: 0.03332414522987031\n"
     ]
    }
   ],
   "source": [
    "original =  (average_embeddings.nbytes)\n",
    "compression_ratio_us = us_total_bytes / original\n",
    "compression_ratio_pq = pq_total_bytes / original\n",
    "\n",
    "print(f'compression ratio us: {compression_ratio_us}')\n",
    "print(f'compression ratio pq: {compression_ratio_pq}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424224"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ids.nbytes + list_codes.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_concept_bitmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1271581/210083219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check bitmap selectivities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg_concept_bitmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mimg_concept_bitmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_concept_bitmap' is not defined"
     ]
    }
   ],
   "source": [
    "# Check bitmap selectivities\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
