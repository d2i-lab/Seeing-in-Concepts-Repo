{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import hashlib\n",
    "from utils import create_new_pickle\n",
    "\n",
    "\n",
    "coco_path = '/data/users/jie/data-slicing/COCO/'\n",
    "embed_path = os.path.join(coco_path, 'embeds/fixed/train2017_vitl_fixed_maskclip/')\n",
    "pickle_path = 'train2017_vitl_fixed_maskclip-fast.pkl'\n",
    "embed_dict = create_new_pickle(embed_path, pickle_path)\n",
    "average_embeddings = embed_dict['average_embeddings']\n",
    "dim = average_embeddings.shape[1]\n",
    "k_coarse = 1023\n",
    "m = 64\n",
    "nbits = 8\n",
    "n_probes = 20\n",
    "\n",
    "train_sample_size = int(128 * math.sqrt(average_embeddings.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict['embed_path'] = embed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is hash f06ed46\n",
      "Loading cached index from cached_index_9a240b6553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 1023 points to 1023 centroids: please provide at least 39897 training points\n",
      "WARNING clustering 1023 points to 1023 centroids: please provide at least 39897 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans trained (hax) 1023\n",
      "Building Flat index\n",
      "Building IVF-Flat index\n",
      "This is training embeds (416117, 512)\n",
      "521 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118287it [01:36, 1228.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "\n",
    "index_pq, index_flat_cpu, index_ivf_flat_cpu, packd, img_concept_bitmap, all_images, pqq, kmeans = \\\n",
    "    data.get_indices(dim, k_coarse, m, nbits, n_probes, embed_dict, train_sample_size=train_sample_size,\n",
    "                     build_ivf_flat=True, cache_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans centroids: 1.998046875 MB\n",
      "packd: 677.0490112304688 MB\n",
      "packd expected:  96.0 MB\n",
      "codebook: 0.5 MB\n",
      "bitmap: 115.40184116363525 MB\n",
      "total: 794.948899269104 MB\n",
      "total: 718.0220565795898 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from scipy import sparse\n",
    "from pympler import asizeof\n",
    "# our memory usage\n",
    "# * kmeans centroids\n",
    "# * quantizer codebook\n",
    "# * bitmap\n",
    "# * packd\n",
    "\n",
    "ksize_bytes = kmeans.centroids.shape[0] * kmeans.centroids.shape[1] * np.dtype(np.float32).itemsize\n",
    "packd_key_bytes = asizeof.asizeof(packd.keys)\n",
    "packd_value_bytes = len(average_embeddings) * m * nbits / 8\n",
    "packd_bytes = packd_key_bytes + packd_value_bytes\n",
    "codebook = faiss.vector_to_array(pqq.centroids).reshape(pqq.M, pqq.ksub, pqq.dsub)\n",
    "codebook_bytes = codebook.nbytes\n",
    "bitmap_bytes = img_concept_bitmap.nbytes\n",
    "sparse_mat_bytes = asizeof.asizeof(sparse.csr_matrix(img_concept_bitmap))\n",
    "\n",
    "print(f'kmeans centroids: {ksize_bytes / 1024 / 1024} MB')\n",
    "print(f'packd: {packd_bytes / 1024 / 1024} MB')\n",
    "print('packd expected: ', packd.memory_usage()['expected'] / 1024 / 1024, 'MB')\n",
    "print(f'codebook: {codebook_bytes / 1024 / 1024} MB')\n",
    "print(f'bitmap: {bitmap_bytes / 1024 / 1024} MB')\n",
    "\n",
    "us_total_bytes = ksize_bytes + packd_bytes + codebook_bytes + bitmap_bytes \n",
    "print(f'total: {us_total_bytes / 1024 / 1024} MB')\n",
    "us_total_bytes_sparse = ksize_bytes + packd_bytes + codebook_bytes + sparse_mat_bytes\n",
    "print(f'total: {us_total_bytes_sparse / 1024 / 1024} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans centroids: 1.998046875 MB\n",
      "inverted list: 685.364444732666 MB\n",
      "codebook: 0.5 MB\n",
      "total: 687.862491607666 MB\n"
     ]
    }
   ],
   "source": [
    "# PQ memory usage\n",
    "# centroids \n",
    "# codebook\n",
    "# inverted list\n",
    "import faiss.contrib.inspect_tools\n",
    "\n",
    "def get_invlist(invlists, l):\n",
    "    \"\"\" returns the inverted lists content. \"\"\"\n",
    "    ls = invlists.list_size(l)\n",
    "    list_ids = np.zeros(ls, dtype='int32') # Can be made 32\n",
    "    x = invlists.get_ids(l)\n",
    "    faiss.memcpy(faiss.swig_ptr(list_ids), x, list_ids.nbytes)\n",
    "    invlists.release_ids(l, x)\n",
    "    x = invlists.get_codes(l)\n",
    "    list_codes = np.zeros((ls, invlists.code_size), dtype='uint8')\n",
    "    faiss.memcpy(faiss.swig_ptr(list_codes), x, list_codes.nbytes)\n",
    "    invlists.release_codes(l, x)    \n",
    "    return list_ids, list_codes\n",
    "\n",
    "\n",
    "ksize_bytes = kmeans.centroids.shape[0] * kmeans.centroids.shape[1] * np.dtype(np.float32).itemsize\n",
    "codebook = faiss.contrib.inspect_tools.get_pq_centroids(index_pq.pq)\n",
    "codebook_bytes = codebook.nbytes\n",
    "list_bytes = 0\n",
    "for i in range(index_pq.invlists.nlist):\n",
    "    list_ids, list_codes = get_invlist(index_pq.invlists, i)\n",
    "    list_bytes += list_ids.nbytes + list_codes.nbytes\n",
    "    # We ignore list_ids because we have an equivalent mapping tracking the vector ids\n",
    "    # list_bytes +=  list_codes.nbytes\n",
    "\n",
    "print(f'kmeans centroids: {ksize_bytes / 1024 / 1024} MB')\n",
    "print(f'inverted list: {list_bytes / 1024 / 1024} MB')\n",
    "print(f'codebook: {codebook_bytes / 1024 / 1024} MB')\n",
    "pq_total_bytes = ksize_bytes + list_bytes + codebook_bytes\n",
    "print(f'total: {pq_total_bytes / 1024 / 1024} MB')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6581531"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packd.used - average_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.157777786254883"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_embeddings.nbytes / 1024 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression ratio us: 0.038512046946555634\n",
      "compression ratio pq: 0.03332414522987031\n"
     ]
    }
   ],
   "source": [
    "original =  (average_embeddings.nbytes)\n",
    "compression_ratio_us = us_total_bytes / original\n",
    "compression_ratio_pq = pq_total_bytes / original\n",
    "\n",
    "print(f'compression ratio us: {compression_ratio_us}')\n",
    "print(f'compression ratio pq: {compression_ratio_pq}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424224"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ids.nbytes + list_codes.nbytes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
